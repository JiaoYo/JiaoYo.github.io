import{d as e,b as n,e as a,o as l,f as t,i,h as r,G as s,a as o,w as u,c as d,B as c,a9 as f,T as p,aa as m,ab as h,ac as v}from"./index-BxLtnPqY.js";import{S as k}from"./spark-md5-DWn9nHa8.js";import{G as y}from"./index-DN9aPBWp.js";const g={key:0},x=1048576,S=e({__name:"index",setup(e){const S=n(!1),N=n(""),H=n(""),w=n(0),b=n({}),A=n(0),I=async e=>{const n=e.target.files[0];N.value=n.name,H.value=await P(n);const a=U(n),l=await m({fileHash:H.value,fileName:N.value,total:a.length});if(l.data.includes("/files"))return b.value={...l,data:""+("https://60.205.130.133:8888"+l.data)},void(w.value=1);A.value=+l.data;for(let t=0;t<a.length;t++)A.value<=t&&await j(a[t],a);setTimeout((()=>{D(N.value,H.value,a.length)}),1e3)},F=n(1),U=e=>{const n=[];let a=0,l=0;for(;a<e.size;){let t=e.slice(a,a+x*F.value);n.push({file:t,chunkIndex:l,fileHash:H.value}),l++,a+=x*F.value}return n};function j(e,n){return new Promise((async(a,l)=>{try{let l=new FormData;l.append("fileName",N.value),l.append("file",e.file),l.append("total",n.length),l.append("fileHash",e.fileHash),l.append("chunkIndex",e.chunkIndex);let t=await h(l);w.value=+t.data.toFixed(2),a(t)}catch(t){l(t)}}))}const P=e=>new Promise((n=>{const a=new FileReader;a.readAsArrayBuffer(e),a.onload=function(e){let a=k.ArrayBuffer.hash(e.target.result);n(a)}})),D=(e,n,a)=>{v({fileName:e,fileHash:n,total:a}).then((e=>{w.value=1,b.value={...e,data:""+("https://60.205.130.133:8888"+e.data)}}))};return(e,n)=>{const m=a("a-input-number"),h=a("a-progress"),v=a("icon-right"),k=a("icon-down"),x=a("a-button");return l(),t("div",null,[i("div",null,[n[2]||(n[2]=i("span",null,"分片大小",-1)),r(m,{modelValue:F.value,"onUpdate:modelValue":n[0]||(n[0]=e=>F.value=e),style:{width:"100px"},placeholder:"Please Enter",class:"input-demo",min:1,max:1e3},null,8,["modelValue"]),n[3]||(n[3]=s(" MB "))]),i("input",{type:"file",ref:"file",onChange:I},null,544),r(h,{percent:w.value},null,8,["percent"]),0!==Object.keys(b.value).length?(l(),t("div",g,[r(y,{codeJson:JSON.stringify(b.value)},null,8,["codeJson"])])):o("",!0),i("div",null,[r(x,{type:"text",onClick:n[1]||(n[1]=e=>S.value=!S.value)},{default:u((()=>[n[4]||(n[4]=s(" 查看代码 ")),S.value?(l(),d(k,{key:1})):(l(),d(v,{key:0}))])),_:1})]),r(p,{name:"fade",mode:"out-in"},{default:u((()=>[c(i("div",null,[n[5]||(n[5]=i("span",null,"vue",-1)),r(y,{codeJson:"\n<template>\n  <div>\n    <div>\n      <span>分片大小</span><a-input-number v-model=\"chunkNum\" :style=\"{ width: '100px' }\" placeholder=\"Please Enter\"\n        class=\"input-demo\" :min=\"1\" :max=\"1000\" />\n      MB\n    </div>\n    <input type=\"file\" ref=\"file\" @change=\"handleFileChange\" />\n    <div v-if=\"dataObj !== '{}'\">\n      {{ dataObj }}\n    </div>\n  </div>\n</template>\n\n<script setup lang=\"ts\">\nimport SparkMD5 from 'spark-md5'\nimport GiCodeView from '@/components/GiCodeView/index.vue';\nimport { ref } from 'vue'\nimport { uploadbig, merge as mergeApi } from '@/apis'\nconst fileName = ref<any>('')\nconst fileHash = ref<any>('')\nconst percent=ref(0)\nconst dataObj = ref({})\nconst fileIndex = ref(0)\nconst handleFileChange = async (e) => {\n  const file = e.target.files[0];\n  fileName.value = file.name\n  fileHash.value = await getFileHash(file);\n  const chunks = createChunks(file);\n  /** 查询文件是否已上传和获取已上传的索引 */\n  const res = await uploadchunk({\n    fileHash: fileHash.value,\n    fileName: fileName.value,\n    total: chunks.length\n  })\n  if (res.data.includes('/files')) {\n    // 已上传\n    dataObj.value = {\n      ...res,\n      data: 'import.meta.env.VITE_API_BASE_URL + res.data'\n    }\n    percent.value=1\n    return\n } else {\n    // 记录上传位置\n    fileIndex.value = +res.data\n  }\n  for (let i = 0; i < chunks.length; i++) {\n    // 断点续传\n    if (fileIndex.value <= i) {\n      await uploadHandler(chunks[i], chunks);\n    }\n  }\n  setTimeout(() => {\n    merge(fileName.value, fileHash.value, chunks.length);\n  }, 1000)\n}\n/** 对文件进行分片 */\nconst chunkNum = ref(1)\nconst chunkSize = 1024 * 1024 ;\nconst createChunks = (file) => {\n  const chunks: any = [];\n  let start = 0;\n  let index = 0;\n  while (start < file.size) {\n    let curChunk = file.slice(start, start + chunkSize* chunkNum.value);\n    chunks.push({\n      file: curChunk,\n      chunkIndex: index,\n      fileHash: fileHash.value,\n    });\n    index++;\n    start += chunkSize* chunkNum.value;\n  }\n  return chunks;\n}\n//分片上传请求接口\nfunction uploadHandler(chunk, chunks) {\n  return new Promise(async (resolve, reject) => {\n    try {\n      let fd = new FormData();\n      fd.append('fileName', fileName.value);\n      fd.append('file', chunk.file);\n      fd.append('total', chunks.length);\n      fd.append('fileHash', chunk.fileHash);\n      fd.append('chunkIndex', chunk.chunkIndex);\n      let result = await uploadbig(fd)\n      percent.value=result.data/10\n      resolve(result)\n    } catch (err) {\n      reject(err)\n    }\n  })\n}\n\n// 通过SparkMD5来获取文件hash\nconst getFileHash = (file) => {\n  return new Promise((resolve) => {\n    const fileReader = new FileReader();\n    fileReader.readAsArrayBuffer(file);\n    fileReader.onload = function (e: any) {\n      let fileMd5 = SparkMD5.ArrayBuffer.hash(e.target.result);\n      resolve(fileMd5);\n    }\n  });\n}\n// 合并切片\nconst merge = (fileName, fileHash, total) => {\n  mergeApi({\n    fileName, fileHash, total\n  }).then((res) => {\n    dataObj.value = {\n      ...res,\n      data: 'import.meta.env.VITE_API_BASE_URL + res.data'\n    }\n  })\n}\n<script>\n"}),n[6]||(n[6]=i("span",null,"upload.controller.ts",-1)),r(y,{codeJson:"\nimport { Controller, Get, Post, Body, UseInterceptors, UploadedFile } from '@nestjs/common';\nimport { UploadService } from './upload.service';\nimport { FileInterceptor } from '@nestjs/platform-express'\nimport { RedisService } from '../common/redis'\nimport {\n  rename,\n  existsSync,\n  mkdirSync,\n  appendFileSync,\n  readFileSync,\n  unlinkSync\n} from 'fs';\nimport { ApiTags, ApiOperation } from '@nestjs/swagger';\n@Controller('upload')\n@ApiTags('上传文件')\nexport class UploadController {\n  constructor(private readonly uploadService: UploadService,\n    private readonly redisService: RedisService) { }\n  @Post('album')\n  @ApiOperation({ summary: '上传图片' })\n  @UseInterceptors(FileInterceptor('file'))\n  upload(@UploadedFile() file) {\n    return { data: '/img/' + file.filename }\n  }\n  @Post('filequery')\n  @ApiOperation({ summary: '查询文件是否上传过' })\n  async filequery(@Body() body) {\n    const { fileName, fileHash, total } = body || {};\n    const chunkDir = 'uploads/' + fileName.split(\".\").pop();\n    const hash = await this.redisService.getValue(fileName)\n    // 如果通过则说明该文件已上传过就直接返回地址\n    if (existsSync({{chunkDir}/{{fileName}}) && hash == fileHash) {\n      return { data: '/files/' + fileName.split(\".\").pop() + '/' + fileName }\n    } else {\n      let index = 0;\n      // 获取文件切片已上传的索引\n      for (let i = 0; i < total; i++) {\n        if (!existsSync(({{chunkDir}/{{fileName}}-{{i}})) {\n          index = i\n          break;\n        }\n      }\n      return { data: String(index) }\n    }\n  }\n  @Post('fileUpload')\n  @ApiOperation({ summary: '切片文件上传' })\n  @UseInterceptors(FileInterceptor('file'))\n  fileUpload(@UploadedFile() file, @Body() body) {\n    const { fileName, fileHash, chunkIndex, total } = body || {};\n    const chunkDir = 'uploads/' + fileName.split(\".\").pop();\n    if (!existsSync(chunkDir)) {\n      mkdirSync(chunkDir);\n    }\n    rename(file.path, {{chunkDir}/{{fileHash}-{{chunkIndex}}, (err) => {\n      if (err) {\n        console.log('err', err);\n      } else {\n        console.log('上传成功');\n      }\n    });\n    return { data: (+chunkIndex + 1) / +total, message: '切片{{chunkIndex}}上传成功' }\n  }\n\n  @Post('fileMerge')\n  @ApiOperation({ summary: '合并切片文件' })\n  fileMerge(@Body() body) {\n    const { fileHash, fileName, total } = body;\n    const mergePathArr = [];\n    const chunkDir = 'uploads/' + fileName.split(\".\").pop();\n    // 找出所有切片文件\n    for (let i = 0; i < total; i++) {\n      mergePathArr.push({{chunkDir}/{{fileHash}}-{{i}});\n    }\n    // 合并切片文件\n    mergePathArr.forEach((path) => {\n      const content = readFileSync(path);\n      appendFileSync({{chunkDir}/({{fileName}}, content);\n    });\n    this.redisService.setValue(fileName, fileHash)\n    // 删除切片文件\n    mergePathArr.forEach((path) => {\n      unlinkSync(path);\n    })\n    return { data: '/files/' + fileName.split(\".\").pop() + '/' + fileName }\n  }\n\n}"}),n[7]||(n[7]=i("span",null,"upload.module.ts",-1)),r(y,{codeJson:"\nimport { Module } from '@nestjs/common';\nimport { UploadService } from './upload.service';\nimport { UploadController } from './upload.controller';\nimport { MulterModule } from '@nestjs/platform-express'\nimport { diskStorage } from 'multer'\nimport { extname, join } from 'path';\nimport { RedisService } from '../common/redis'\n@Module({\n  imports: [MulterModule.register({\n    storage: diskStorage({\n      destination: 'uploads', // 设置上传文件的路径\n      filename: (_, file, callback) => {\n        const fileName = {{new Date().getTime() + extname(file.originalname)}}\n        return callback(null, fileName)\n      }\n    })\n  })],\n  controllers: [UploadController],\n  providers: [UploadService,RedisService]\n})\nexport class UploadModule { }"})],512),[[f,S.value]])])),_:1})])}}});export{S as _};
